{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{-1: 0.4, 1: 0.6}\n",
      "标签 -1 的长度 6\n",
      "{'3|-1': 0.16666666666666666}\n",
      "{'3|-1': 0.16666666666666666, 'L|-1': 0.16666666666666666}\n",
      "标签 1 的长度 9\n",
      "{'3|-1': 0.16666666666666666, 'L|-1': 0.16666666666666666, '3|1': 0.4444444444444444}\n",
      "{'3|-1': 0.16666666666666666, 'L|-1': 0.16666666666666666, '3|1': 0.4444444444444444, 'L|1': 0.4444444444444444}\n",
      "{-1: 0.01111111111111111, 1: 0.11851851851851851}\n",
      "[3, 'L'] 属于 1\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes(object):\n",
    "    def getTrainSet(self):\n",
    "        dataSet = pd.read_csv('./naivebayes_data.csv')\n",
    "        #print(dataSet)\n",
    "        dataSetNP = np.array(dataSet)  #将数据由dataframe类型转换为数组类型\n",
    "        #print(dataSetNP)\n",
    "        trainData = dataSetNP[:,0:dataSetNP.shape[1]-1]   #训练数据x1,x2\n",
    "        labels = dataSetNP[:,dataSetNP.shape[1]-1]        #训练数据所对应的所属类型Y\n",
    "        return trainData, labels\n",
    "\n",
    "    def classify(self, trainData, labels, features):\n",
    "        #求labels中每个label的先验概率\n",
    "        labels = list(labels)    #转换为list类型\n",
    "        P_y = {}#存入label的概率\n",
    "        for label in labels:#计算每一个类别的概率\n",
    "            P_y[label] = labels.count(label)/float(len(labels)) \n",
    "        print(P_y)\n",
    "        '''\n",
    "        ******************极大似然估计----朴素贝叶斯*******************\n",
    "        D = {x1,x2,X3........}\n",
    "        argmax P(a|D):给定D的情况下，起一个a参数使得概率最大\n",
    "        根据贝叶斯定理：p(a|D) = (p(D|a)p(a))/p(D)\n",
    "        \n",
    "        概率派认为p(a)不变，且p(D)也已知，因此可以转换为 argmax P(D|a),“朴素”假设D的特征x1,x2....相互独立\\\n",
    "        一次上式可以转换为：argmax P(D|a)=argmax {P(x1|a)P(x2|a)P(x3|a)......}\n",
    "        \n",
    "        \n",
    "        ****************************************************************\n",
    "        \n",
    "       由于假设各特征之间相符独立，所以P(X|y) = P(x1|y)P(x2|y) \n",
    "       那么如何求P(x1|y)P(x2|y)？？？？\n",
    "       统计得到各类别下各特征属性的条件概率\n",
    "        '''\n",
    "        #后验概率\n",
    "        P_x_y = {}\n",
    "        for y in P_y.keys():\n",
    "            y_index = [i for i, label in enumerate(labels) if label == y]  # labels中出现y值的所有数值的下标索引\n",
    "            #找出标签为  -1 的所有索引分别为0, 1, 4, 5, 6, 14\n",
    "            #找出标签为  1 的所有索引分别为2, 3, 7, 8, 9, 10, 11, 12, 13\n",
    "            print('标签',y,'的长度',len(y_index))\n",
    "            for j in range(len(features)):  # features[0] 在trainData[:,0]中出现的值的所有下标索引\n",
    "                x_index = [i for i, feature in enumerate(trainData[:,j]) if feature == features[j]]\n",
    "                #找出训练数据中第一列 与 测试数据第一列相等 的索引分别为:5, 6, 7, 8, 9\n",
    "                #找出训练数据中第一列 与 测试数据第二列相等 的索引分别为:0, 3, 4, 5\n",
    "                '''\n",
    "                j =0:trainData[:,j]取出训练数据的第一列，如果第一列的值与测试数据第一列的值相等就得到该测试集数据的索引\n",
    "                j =1:.................................................................................................\n",
    "                '''\n",
    "                \n",
    "                x_y_count = len(set(x_index) & set(y_index))   # set(x_index)&set(y_index)列出两个表相同的元素\n",
    "                '''\n",
    "                外部第一次循环\n",
    "                第一次：2|-1----->x_index与y_index重合的索引有5,6，因此，内第一次循环 得到P(2|-1) = 2/6\n",
    "                第二次：S|-1----->x_index与y_index重合的索引有0,4,5，因此，内第二次新婚换 得到P(S|-1) = 3/6\n",
    "                外部第二次循环\n",
    "                第一次：2|1----->x_index与y_index重合的索引有7,8,9，因此，内第一次循环 得到P(2|1) = 3/9\n",
    "                第二次：S|1----->x_index与y_index重合的索引有3，因此，内第二次新婚换 得到P(S|1) = 1/9\n",
    "                '''\n",
    "                pkey = str(features[j]) + '|' + str(y)\n",
    "                #print(pkey)\n",
    "                P_x_y[pkey] = x_y_count / float(len(y_index))#公式（1）\n",
    "                print(P_x_y)\n",
    "        \n",
    "        #求[2,'S']所属类别\n",
    "        F = {}   #[2,'S']属于各个类别的概率\n",
    "        for y in P_y:\n",
    "            F[y] = P_y[y]\n",
    "            #print(F)\n",
    "            for x in features:\n",
    "                F[y] = F[y]*P_x_y[str(x)+'|'+str(y)]     #P[y/X] = P[X/y]*P[y]/P[X]，分母相等，比较分子即可，所以有F=P[X/y]*P[y]=P[x1/Y]*P[x2/Y]*P[y]\n",
    "        print(F)\n",
    "        features_label = max(F, key=F.get)  #概率最大值对应的类别\n",
    "        return features_label\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nb = NaiveBayes()\n",
    "    # 训练数据\n",
    "    trainData, labels = nb.getTrainSet()\n",
    "    #print(trainData[:,0])\n",
    "    print(type(labels))\n",
    "    features = [3,'L']\n",
    "    # 该特征应属于哪一类\n",
    "    result = nb.classify(trainData, labels, features)\n",
    "    print(features,'属于',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###################贝叶斯估计----朴素贝叶斯------多项式模型（特征离散）#####################\n",
    " P_x_y[pkey] = x_y_count / float(len(y_index)) 公式（1）\n",
    " 条件概率的贝叶斯估计：\n",
    " P_x_y[pkey] = （x_y_count + A） / （float(len(y_index))+Si*A）公式（2），Si表示每一维特征可能取值的个数\n",
    " 其中A>=0，A=0时就是极大似然估计，A=1时，叫拉普拉斯平滑\n",
    " \n",
    " 作用：例如某一维特征在训练样本中没有出现过，则会导致y(xi|y) = 0,导致后验概率为零，加上平滑就能克服这一问题\n",
    " \n",
    "        \n",
    "        \n",
    " ################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################朴素贝叶斯----高斯模型（特征连续）##############################\n",
    "处理方法：\n",
    "当特征是连续变量的时候，不采取平滑使用多项式模型就会导致很多P(xi|yk)=0,即使使用了平滑，得到的后验概率也不能描述真实情况，因此采用高斯模型。\n",
    "步骤 1.计算每个特征的平均值和方差，得到正态分布的密度函数，通过密度函数就能计算的到测试数据的密度函数值\n",
    "    2.将密度函数值作为条件概率的值\n",
    "    3.通过朴素贝叶斯方法计算测试样本所属类别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python实现基于高斯模型的朴素贝叶斯算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB(object):\n",
    "    def __init__(self,alpha = 1.0,fit_prior=True):\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior = None\n",
    "        self.classes = None\n",
    "        self.conditional_prob = None\n",
    "        self.predict_prob = None\n",
    "        '''\n",
    "        fit_class:是否学习类的先验概率，False则使用统一的先验\n",
    "        class_prior:类的先验概率，如果指定，则先验不能根据数据调整\n",
    "        \n",
    "        '''\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        #计算类别y的先验概率\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        if self.class_prior == None:#先验概率没有指定\n",
    "            class_num = len(self.classes)\n",
    "            if not self.fit_prior:\n",
    "                self.class_prior = [1.0/class_num for i in range(class_num)]\n",
    "            else:\n",
    "                self.class_prior = {}\n",
    "                for d in self.classes:\n",
    "                    c_num = np.sum(np.equal(y,d))\n",
    "                    self.class_prior[d]=(c_num+self.alpha) / (float(len(y) + class_num * self.alpha))\n",
    "        #print(self.class_prior)           \n",
    "        #计算条件概率------多项式\n",
    "        self.conditional_prob = {}#{x1|y1:p1,x2|y1:p2,.....,x1|y2:p3,x2|y2:p4,.....}\n",
    "        y = list(y)\n",
    "        for yy in self.class_prior.keys():\n",
    "            y_index = [i for i,label in enumerate(y) if label == yy]\n",
    "        #print(y_index)#标签的先验概率\n",
    "            for i in range(len(x)):\n",
    "                x_class = np.unique(x[i])\n",
    "                for c in list(x_class):\n",
    "                    x_index = [x_i for x_i,value1 in enumerate(list(x[i])) if value1 == c]\n",
    "                    xy_count = len(set(x_index) & set(y_index))\n",
    "                    pkey = str(c) + '|' + str(yy)\n",
    "                    self.conditional_prob[pkey] = (xy_count+self.alpha) / (float(len(y_index))+len(list(np.unique(x[i]))))\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self,X_test):#此处只能对一个样本输入测试，加循环可以多个样本一个测试，高斯模型有实现\n",
    "        self.predict_prob = {}\n",
    "        for i in self.classes:\n",
    "            self.predict_prob[i] = self.class_prior[i]\n",
    "            \n",
    "            for d in X_test:\n",
    "                tkey = str(d) + '|'+ str(i)\n",
    "                self.predict_prob[i] = self.predict_prob[i]*self.conditional_prob[tkey]\n",
    "        label = max(self.predict_prob, key=self.predict_prob.get)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultinomialNB at 0x816c358>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "                      [1,1,1,1,1,2,2,2,2,2,3,3,3,3,3],\n",
    "                      ['S','M','M','S','S','S','M','M','L','L','L','M','M','L','L']\n",
    "             ])\n",
    "#X = X.T\n",
    "y = np.array([-1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,-1])\n",
    "\n",
    "mnb = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "mnb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [2,'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 0.06100217864923746, 1: 0.0326797385620915}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussionNB(object):#计算条件概率的方法不一样\n",
    "    def __init__(self,fit_prior=True):\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior = None\n",
    "        self.classes = None\n",
    "        self.mean = None\n",
    "        self.var = None\n",
    "        self.predict_prob = None\n",
    "        '''\n",
    "        fit_class:是否学习类的先验概率，False则使用统一的先验\n",
    "        class_prior:类的先验概率，如果指定，则先验不能根据数据调整\n",
    "        \n",
    "        '''\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        #计算类别y的先验概率\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        if self.class_prior == None:#先验概率没有指定\n",
    "            class_num = len(self.classes)\n",
    "            if not self.fit_prior:\n",
    "                self.class_prior = [1.0/class_num for i in range(class_num)]\n",
    "            else:\n",
    "                self.class_prior = {}\n",
    "                for d in self.classes:\n",
    "                    c_num = np.sum(np.equal(y,d))\n",
    "                    self.class_prior[d]=(c_num) / (float(len(y)))\n",
    "        #print(self.class_prior)           \n",
    "        #计算条件概率------多项式\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        y = list(y)\n",
    "        for yy in self.class_prior.keys():\n",
    "            y_index = [i for i,label in enumerate(y) if label == yy]\n",
    "        #print(y_index)#标签的先验概率\n",
    "            for i in range(len(x)):\n",
    "                x_class =[]\n",
    "                for ii in y_index:\n",
    "                    x_class.append(x[i][ii])\n",
    "                    #print(x_class)\n",
    "                    pkey = '特征'+str(i)+'|'+'类别'+str(yy)\n",
    "                    mean = np.mean(x_class)\n",
    "                    var = np.var(x_class)\n",
    "                    self.mean[pkey] = mean\n",
    "                    self.var[pkey] = var\n",
    "        return self\n",
    "    def _calculat_prob_gaussion(self,mu,sigma,x):\n",
    "        \n",
    "        prob = ( 1.0/(sigma * np.sqrt(2 * np.pi)) *\n",
    "                        np.exp( - (x - mu)**2 / (2 * sigma**2)) )\n",
    "        return prob\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        labels = []\n",
    "        self.predict_prob = []\n",
    "        predict_prob_ = {}\n",
    "        for d in range(len(X_test)):\n",
    "            x_test = X_test[d]\n",
    "            #print(x_test)\n",
    "            for yy in self.class_prior.keys():\n",
    "                predict_prob_[yy] = self.class_prior[yy]\n",
    "                for i,x in  enumerate(list(x_test)):\n",
    "                    #print(x)\n",
    "                    tkey = '特征'+str(i)+'|'+'类别'+str(yy)\n",
    "                    #print(tkey)\n",
    "                    mu = self.mean[tkey] \n",
    "                    #print('mu值',mu)\n",
    "                    sigma = self.var[tkey] \n",
    "                    #print('sigma值',sigma)\n",
    "                    prob = self._calculat_prob_gaussion(mu,sigma,x)\n",
    "                    #print(prob)\n",
    "                    predict_prob_[yy] = predict_prob_[yy]*prob\n",
    "                    #print(predict_prob_[yy])\n",
    "            \n",
    "            print(predict_prob_)\n",
    "            new_predict_prob_ = predict_prob_.copy()\n",
    "            self.predict_prob.append(new_predict_prob_)\n",
    "            label = max(predict_prob_, key=predict_prob_.get)\n",
    "            labels.append(label)   \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GaussionNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "                      [6,5.92,5.58,5.92,5,5.5,5.42,5.75],\n",
    "                      [180,190,170,165,100,150,130,150],\n",
    "                      [12,11,12,10,6,8,7,9]\n",
    "             ])\n",
    "y = np.array([1,1,1,1,-1,-1,-1,-1])#1表示男 -1表示女"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussionNB at 0x4f29668>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 5.844387841911232e-11, 1: 2.7545821476829804e-237}\n",
      "{-1: 4.352008789594488e-84, 1: 2.3065100816905203e-283}\n",
      "{-1: 1.1875557253200766e-10, 1: 0.0004072906106081061}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1, 1]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[5,130,8],[6.8,170,11.5],[5.8,170,10]]\n",
    "gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{-1: 5.844387841911232e-11, 1: 2.7545821476829804e-237},\n",
       " {-1: 4.352008789594488e-84, 1: 2.3065100816905203e-283},\n",
       " {-1: 1.1875557253200766e-10, 1: 0.0004072906106081061}]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
